"""
Bilibili Content Analyzer - Main Analysis Module

This module provides the main orchestration for the Bilibili content analysis
workflow, including data collection, analysis, and visualization.
"""

import os
import sys
import argparse
import time
from datetime import datetime
import logging
from typing import Optional, Dict, Any

from .data_collector import BilibiliDataCollector
from .data_analyzer import DataAnalyzer
from .visualizer import Visualizer
from .config import DATA_STORAGE, SEARCH_KEYWORDS, DATE_RANGE


class BilibiliAnalyzer:
    """Main orchestrator for Bilibili content analysis workflow."""
    
    def __init__(self, config_path: Optional[str] = None, output_dir: Optional[str] = None):
        self.logger = self._setup_logger()
        self.collector = BilibiliDataCollector()
        self.analyzer = DataAnalyzer()
        self.visualizer = Visualizer()
        self.output_dir = output_dir or DATA_STORAGE['output_dir']
        self._ensure_directories()
    
    def _setup_logger(self) -> logging.Logger:
        """Setup main application logger."""
        logger = logging.getLogger('BilibiliAnalyzer')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            log_file = os.path.join(DATA_STORAGE['logs_dir'], 'main.log')
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setLevel(logging.INFO)
            
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(formatter)
            console_handler.setFormatter(formatter)
            
            logger.addHandler(file_handler)
            logger.addHandler(console_handler)
        
        return logger
    
    def _ensure_directories(self):
        """Ensure all necessary directories exist."""
        for dir_path in DATA_STORAGE.values():
            os.makedirs(dir_path, exist_ok=True)
    
    def collect_only(self, force_recollect: bool = False) -> bool:
        """Run data collection only.
        
        Args:
            force_recollect: Whether to force re-collection of data
            
        Returns:
            bool: True if successful, False otherwise
        """
        print("\n" + "="*60)
        print("Starting Data Collection Phase")
        print("="*60)
        
        enhanced_data_file = os.path.join(DATA_STORAGE['processed_data_dir'], 'enhanced_videos_data.csv')
        
        if os.path.exists(enhanced_data_file) and not force_recollect:
            print(f"Found existing data file: {enhanced_data_file}")
            print("Use --force-recollect to re-collect data")
            return True
        
        self.logger.info("Starting data collection")
        start_time = time.time()
        
        try:
            # Collect basic data
            print(f"Collecting keywords: {', '.join(SEARCH_KEYWORDS)}")
            print(f"Time range: {DATE_RANGE['start_year']}-{DATE_RANGE['end_year']}")
            
            df = self.collector.collect_all_data()
            
            if df.empty:
                print("Data collection failed - no data retrieved")
                return False
            
            print(f"Basic data collection completed: {len(df)} videos")
            
            # Enhance data
            print("Enhancing video data...")
            enhanced_df = self.collector.enhance_video_data(df)
            
            elapsed_time = time.time() - start_time
            print(f"Data collection completed! Time: {elapsed_time/60:.1f} minutes")
            print(f"Data saved to: {DATA_STORAGE['processed_data_dir']}")
            
            self.logger.info(f"Data collection completed: {len(enhanced_df)} videos")
            return True
            
        except Exception as e:
            self.logger.error(f"Data collection failed: {e}")
            print(f"Data collection failed: {e}")
            return False
    
    def run_data_analysis(self):
        """è¿è¡Œæ•°æ®åˆ†æ"""
        print("\n" + "="*60)
        print("å¼€å§‹æ•°æ®åˆ†æé˜¶æ®µ")
        print("="*60)
        
        self.logger.info("å¼€å§‹æ•°æ®åˆ†æ")
        start_time = time.time()
        
        try:
            # åŠ è½½æ•°æ®
            print("ğŸ“‚ åŠ è½½æ•°æ®...")
            df = self.analyzer.load_data()
            
            if df.empty:
                print("æ²¡æœ‰å¯åˆ†æçš„æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®é‡‡é›†")
                return False
            
            print(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            print("æ­£åœ¨è¿›è¡Œç»¼åˆåˆ†æ...")
            report = self.analyzer.generate_comprehensive_report(df)
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            print("ä¿å­˜åˆ†æç»“æœ...")
            self.analyzer.save_processed_data(df)
            
            elapsed_time = time.time() - start_time
            print(f"æ•°æ®åˆ†æå®Œæˆï¼è€—æ—¶: {elapsed_time:.1f} ç§’")
            
            # æ˜¾ç¤ºåˆ†ææ¦‚è§ˆ
            self._display_analysis_summary(report)
            
            self.logger.info("æ•°æ®åˆ†æå®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"æ•°æ®åˆ†æå¤±è´¥: {e}")
            print(f"æ•°æ®åˆ†æå¤±è´¥: {e}")
            return False
    
    def run_visualization(self):
        """è¿è¡Œæ•°æ®å¯è§†åŒ–"""
        print("\n" + "="*60)
        print("å¼€å§‹æ•°æ®å¯è§†åŒ–é˜¶æ®µ")
        print("="*60)
        
        self.logger.info("å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
        start_time = time.time()
        
        try:
            self.visualizer.generate_all_visualizations()
            
            elapsed_time = time.time() - start_time
            print(f"å¯è§†åŒ–ç”Ÿæˆå®Œæˆï¼è€—æ—¶: {elapsed_time:.1f} ç§’")
            
            charts_dir = os.path.join(DATA_STORAGE['output_dir'], 'charts')
            print(f"å›¾è¡¨ä¿å­˜ä½ç½®: {charts_dir}")
            
            self.logger.info("å¯è§†åŒ–ç”Ÿæˆå®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            print(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    def _display_analysis_summary(self, report: dict):
        """æ˜¾ç¤ºåˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("åˆ†æç»“æœæ‘˜è¦")
        print("="*60)
        
        overview = report.get('overview', {})
        
        print(f"åˆ†ææœŸé—´: {overview.get('date_range', 'N/A')}")
        print(f"è§†é¢‘æ€»æ•°: {overview.get('total_videos', 0):,}")
        print(f"æ€»æ’­æ”¾é‡: {overview.get('total_views', 0):,}")
        print(f"å¹³å‡æ’­æ”¾é‡: {overview.get('avg_views', 0):,.0f}")
        print(f"å¹³å‡å‚ä¸åº¦: {overview.get('avg_engagement_rate', 0):.3f}%")
        
        # æƒ…æ„Ÿåˆ†å¸ƒ
        sentiment_dist = report.get('sentiment_analysis', {}).get('sentiment_distribution', {})
        if sentiment_dist:
            print(f"\næƒ…æ„Ÿåˆ†å¸ƒ:")
            total_videos = sum(sentiment_dist.values())
            for sentiment, count in sentiment_dist.items():
                percentage = count / total_videos * 100
                sentiment_name = {"positive": "ç§¯æ", "neutral": "ä¸­æ€§", "negative": "æ¶ˆæ"}.get(sentiment, sentiment)
                print(f"   {sentiment_name}: {count:,} ({percentage:.1f}%)")
        
        # çƒ­é—¨å…³é”®è¯
        top_keywords = report.get('content_themes', {}).get('top_keywords', [])
        if top_keywords:
            print(f"\nçƒ­é—¨å…³é”®è¯ (Top 10):")
            for i, (keyword, weight) in enumerate(top_keywords[:10], 1):
                print(f"   {i:2d}. {keyword} (æƒé‡: {weight:.3f})")
        
        # å¹´åº¦è¶‹åŠ¿
        yearly_trends = report.get('time_trends', {}).get('yearly_trends', {})
        if yearly_trends:
            print(f"\nå¹´åº¦è¶‹åŠ¿:")
            for year, data in yearly_trends.items():
                print(f"   {year}: {data.get('video_count', 0)} ä¸ªè§†é¢‘, "
                      f"å¹³å‡æ’­æ”¾é‡ {data.get('avg_views', 0):,.0f}")
    
    def run_full_analysis(self, force_recollect: bool = False):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("Bç«™æ‰§è¡ŒåŠ›å†…å®¹åˆ†æé¡¹ç›®")
        print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        overall_start_time = time.time()
        
        # æ•°æ®é‡‡é›†
        if not self.run_data_collection(force_recollect):
            print("æ•°æ®é‡‡é›†å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False
        
        # æ•°æ®åˆ†æ
        if not self.run_data_analysis():
            print("æ•°æ®åˆ†æå¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False
        
        # æ•°æ®å¯è§†åŒ–
        if not self.run_visualization():
            print("æ•°æ®å¯è§†åŒ–å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
            return False
        
        # å®Œæˆ
        total_time = time.time() - overall_start_time
        print("\n" + "="*60)
        print("åˆ†æé¡¹ç›®å®Œæˆï¼")
        print("="*60)
        print(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        print(f"ç»“æœæ–‡ä»¶ä½ç½®: {DATA_STORAGE['output_dir']}")
        print("\nç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   â€¢ åˆ†ææŠ¥å‘Š: analysis_report.json")
        print(f"   â€¢ æ•°æ®æ–‡ä»¶: analyzed_data.csv, analyzed_data.xlsx")
        print(f"   â€¢ å›¾è¡¨ç›®å½•: charts/")
        print(f"   â€¢ äº¤äº’å¼ä»ªè¡¨æ¿: charts/interactive_dashboard.html")
        
        return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Bç«™æ‰§è¡ŒåŠ›å†…å®¹åˆ†æé¡¹ç›®')
    parser.add_argument('--mode', choices=['collect', 'analyze', 'visualize', 'full'], 
                       default='full', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--force-recollect', action='store_true', 
                       help='å¼ºåˆ¶é‡æ–°é‡‡é›†æ•°æ®')
    
    args = parser.parse_args()
    
    project = ExecutionAnalysisProject()
    
    try:
        if args.mode == 'collect':
            success = project.run_data_collection(args.force_recollect)
        elif args.mode == 'analyze':
            success = project.run_data_analysis()
        elif args.mode == 'visualize':
            success = project.run_visualization()
        else:  # full
            success = project.run_full_analysis(args.force_recollect)
        
        if success:
            print("\nç¨‹åºæ‰§è¡ŒæˆåŠŸ")
            sys.exit(0)
        else:
            print("\nç¨‹åºæ‰§è¡Œå¤±è´¥")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()